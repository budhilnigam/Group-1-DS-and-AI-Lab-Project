

###  Key Research Papers

| Title | Summary | Source |
|-------|---------|--------|
| **An Empirical Evaluation of LLM-Based Approaches for Code Vulnerability Detection: RAG, SFT, and Dual-Agent Systems** | Compares Retrieval-Augmented Generation (RAG), Supervised Fine-Tuning (SFT), and dual-agent LLMs for detecting software vulnerabilities. Uses real-world codebases and Big-Vul dataset. Shows RAG improves precision in identifying security flaws. |   [arXiv.org](https://arxiv.org/pdf/2601.00254) |
| **Evaluating Open-Source LLMs in RAG Systems: A Benchmark on Code Tasks** | Benchmarks open-source LLMs (e.g., Mistral, LLaMA) in RAG pipelines using the RAGAS framework. Focuses on retrieval quality and generation accuracy in code-related tasks. |   [Springer](https://link.springer.com/article/10.1007/s44427-025-00006-3) |
| **Awesome Generative AI Guide – RAG Research Table** | A curated GitHub repository tracking impactful RAG research from 2023–2026. Includes papers on RAG for code understanding, agentic planning, and tool-augmented LLMs. |   [Github](https://github.com/aishwaryanr/awesome-generative-ai-guide/blob/main/research_updates/rag_research_table.md) |
